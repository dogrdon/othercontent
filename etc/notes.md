## Othercontent

A meandering look into the makeup of clickbait content providers on the web. Content farm studies. Contenticulture.

### Services that create spam links (to "share content")

* :white_check_mark: outbrain
* :white_check_mark: taboola
* :interrobang: zemanta 
* :white_check_mark: revcontent
* :interrobang: ayboll
* :white_check_mark: Content.ad
* :white_medium_square: adblade
* :white_medium_square: pubmatic
* :white_medium_square: zergnet
* :white_medium_square: nrelate
* :interrobang: MGID


### Starting list:
*see ./meta/*

**outbrain**

* bleacherreport.com
* nydailynews.com
* tmz.com

**taboola**

* examiner.com
* nbcnews.com
* theblaze.com 

**content.ad**

* traveltune.com - riddled with it, but not sure any from content.ad?
* patheos.com - religious site, might be interesting to see what pops up here
* wably.com - lifestyle home and garden type site, lots of stuff

**revcontent**

>> ugh, image html looks like this: 
`<div class="rc-photo" style="background-image: url(&quot;//img.revcontent.com/?url=https://revcontent-production.s3.amazonaws.com/content/images/1461875891.jpg&amp;static=true&amp;pos=face&amp;h=315&amp;w=420&amp;static=true&quot;); height: 231px;">  </div>`

* ~ibtimes.com~ - not as interesting, only links to other ibtimes content
* ~dailycooking.com~ - only on homepage and only links back to revcontent service
* tpnn.com - yeah, lots of crap here.
* redorbit.com - more crap here, different crap, great crap
* worldstarhiphop.com - not on top of quantcast, but links to other sites (extremely clickbaity, very low brow stuff)


### Initial Steps

* :white_check_mark: grab information about sites that use which content farm technology on their sites from builtwith.
* :white_check_mark: for a selection of these different content farms (see above with '*'), get the top 3 (for now) based on quantcast rank ( as of ~12/28/2015 - though not sure how up to date, or accurate the ranking is, should be good enough for approximation).
* :white_check_mark: generate a profile for each of the sites consisting of 1) xpath to main articles on front page, 2) xpath to content farm location on article page 3) xpath to any content farm locations on the front page.
* :white_check_mark: also generate a profile for each of of the content farm locations generally consisting of: content farm it came from, image used for each link, title for link, data-target (or where it actually goes) for link, where it was originally found, and descriptive text if available.
* :white_medium_square: establish a schedule around which to gather these links, only adding new content, not adding existing. if necessary run an automatic server to go and fetch these occassionaly
* :white_medium_square: gather a few thousand of these to begin with and review
* :white_medium_square: check to see if time of day, or any agent spoofing makes a different
* :white_medium_square: ideally grab up to 1 million of these if possible.


### Required set up for scraping ajax loaded content networks

    brew install phantomjs
    gem install capybara
    gem install poltergeist
    gem install nokogiri


### Metadata

* **link** - url to the content the item is pointing to
* **headline** - clickbait text
* **image** - clickbait image
* **provider** - the provider or ad network it comes from
* **website** - url to original webpage content is found on
* **datetime** - datetime item was grabbed
* **frequency** - number of times link to this has been seen by spider


#### Metadata Questions

* Should we ignore repeats?
* If so, how do we determine a repeat. Same image, same text, same url? This might not be reliable (these links might be nutso)
* If counting frequency, might the same content be at another URL? (let's analyze a few thousand first)
* How to make sure we get something like a persistent link to the content? These redirects might burn out
* Archival matters, should we be doing WARC here? Of what? 


### Other considerations

* The person who probably did all this way better and more thoroughly than i ever will: http://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/ -> http://clickotron.com/, though this is regarding actual headlines from places like huffington post, buzzfeed, upworthy, gawker. 

* The approach here is to focus on image and text generated by the even more insidious content farms covering the web in a sheen of clickchum.

* On looking into a sports site, the content is at least context specific...it's all recommendations for sports stuff.

* There are a number of different ways a site can configure all of this paid-for content. TMZ is so far the worst: it's everywhere. 

* The British sites I've seen here seem to be a) a little more conservative in their placement of them b) they acknowledge that they are advertisements.

* There's stuff on the homepage, theres stuff at the bottom and sidebars there. Some of it is all mixed up with stuff from the site you are actually one. On the article pages there are also bottom and possibly multiple sidebar content spaces from multiple different providers. Fortunately the semantics are the same provider to provider across different sites. 

* Do these services provide APIs?

* Is there some backdoor to understanding how these services work?

* How to tell if something has been written by human or machine?

* What happens as sites pick up and drop content networks over a short period of time?

